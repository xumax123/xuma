# 掩盖重码的把戏
重码率与输入法类型及编码方案关系最为密切，极少有输入法将自已的重码字公之与众。
## 掩盖重码的手段
近年来，网上竟然有输入法宣称只有几十个重码字，实在令行家难以置信。当然他们的重码字是不能公布的。因为，一公布就会露马脚，这里有三种典型的情况：


## 一、输入法作者自定重码字标准
为了将自创输入法推广出去，在谈及重码字数量时，他们采用了灵活的说法。并堂而皇之地认为：有简码的重码字就不再是重码字，理由是这些字可以通过简码来输入。
在这种心态支配下，他们只将没有简码字的重码字确定为重码字，如此，情况就大不一样了，原来被认为的600个重码字，现在就只剩下不到200个了。
我们认为：重码字作为输入法品质优劣性的重要指标，应以全码字为定义对象，否则就没有定义的必要了。

## 二、采用“取头断尾”法来掩盖真实的重码字
假设输入法真正的重码字有600个（设为300组），想让用户认为无重码，只要从构成重码的每对中选取一个字，也就是选择300个字设置成简码字，然后将该字的全码舍去即可。
简码字是从众多符合筛选条件的字中严格挑选出的高频字，如果将原本要安置高频字的简码空位让给某些重码字，让这些“滥竽充数”者占据主位，势必会影响总体输入效率。

## 三、在编码对象上做文章
国标一级汉字共有3755个，一般来说，常用字都在其中，二级汉字共有3008个，其中大部分为冷避字。输入法的基本编码对象应是这6763个汉字。如果一个输入法作者在这个基本编码对象上做点文章，掩盖自身的重码率，那也是容易做到的。
若有重码字600个，只要在重码字中选择120个相对冷避的汉字删除掉，与之相配对的另一重码字也就不存在了，这样一来，总量上就少了240个重码字。

# 重码的绝对几率
最为常见的是以26个字母键、码位数为4的输入法。因此，我们就以这种典型的输入法来讨论重码字发生的几率。
这种典型的输入法，其编码空间总量为：456976位（26的4次方），而编码对象是6763个国标汉字（不加入词组），在这种条件下，所编出的输入法，其编码空间占用的情况是：

456976÷6763=67.57，也就是：6763个字占用了约六十八分之一的编码空间
此时，每输入1个汉字，其重码的发生几率为：67.57分之1（456976除以(6763-1)=67.58），或者说每输入67.58个汉字后，就会产生一对重码，这样累计，输完6763个汉字，会产生6763乘以1/67.58=100.1对重码。从这个原理上来说，以26个字母键、码位数为4编码的输入法，其重码发生的几率所产生的重码为100对。

以上是从绝对均衡的条件下预测的。实际上，汉字外形结构与读音的类同性、编码规则、字根规则的原则性等因素，影响汉字在编码空间内均衡分布，其结果只会增大重码的发生几率。

就全形码输入法来说，汉字结构的类同性造成重码发生几率的增加，首先表现在构字能力特强的一些部件上，如“口”、“亻”、“艹”、 “钅”、“氵”、“木”等，造成某些汉字聚集在编码空间的某一区间或层面上，从而使重码的发生几率增高；其次表现在某些相近特征的汉字上，产生“惰性”重码。每种编码规则类型，都有其相应的“惰性”重码。如“赢羸蠃嬴” 、“微徽徵”、“龆龉”、“蝥蟊”等汉字相对全形码而言，就是“惰性”重码，在编码规则确定为“一二三末”之后， 无论字根位置如何调整，这些重码都在所难免。

以上编码空间占用原理告诉我们：以26个字母键、码位数为4编码的输入法，重码发生的绝对几率所产生的重码为100对，这是理论上的临界值，实践中，设计者降低重码的理性期望值，是不能少于这个临界值的。少于这个临界值的期望，是不现实的